{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%bash\nrm -rf *\n\ngdown \"1fqx3CFdsuOxwW2hjMRhviSUOIzwBlV-J\"\nunzip dev_phase.zip > /dev/null\n\ngit clone \"https://github.com/Toavina00/Polar-SemEval-2026-Task-9.git\"\nmv Polar-SemEval-2026-Task-9/src .","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\n\nimport torch._dynamo\ntorch._dynamo.config.suppress_errors = True\n\nimport time\nimport tracemalloc\nimport pprint\n\nfrom sklearn.metrics import f1_score\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModel,\n    DataCollatorWithPadding,\n    EarlyStoppingCallback,\n)\n\nfrom src.dataset import PolarDataset, load_dataset\nfrom src.model import PolarModel, PolarTrainer, PolarTrainingArgs\nfrom src.utils import compile_submission","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"LANGUAGES = [\"eng\", \"hau\", \"swa\"]\nROOT_DIR = \"./\"\n\ndef init_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    np.random.seed(seed)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ncheckpoint = \"jhu-clsp/mmBERT-base\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_metrics(p):\n    probs = torch.sigmoid(torch.from_numpy(p.predictions))\n    preds = (probs > 0.5).int().numpy()\n    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}\n\nBATCH_SIZE = 16\n\ntrain_dir = lambda subtask_dir: os.path.join(ROOT_DIR, f\"subtask{subtask_dir}\", \"train\")\ndev_dir = lambda subtask_dir: os.path.join(ROOT_DIR, f\"subtask{subtask_dir}\", \"dev\")\n\nexperiment_results = {}\n\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\ntraining_args = PolarTrainingArgs(\n    output_dir=f\"./\",\n    num_train_epochs=10,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    lr_scheduler_type='linear',\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    # fp16=True,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    logging_steps=100,\n    disable_tqdm=False,\n    report_to=\"none\",\n)\n\ndataset = [\n    load_dataset(\n        train_dir(2),\n        LANGUAGES,\n        tokenizer,\n        train=True,\n        val_size=0.2,\n        random_state=42,\n        stratify=False,\n    ),\n    load_dataset(\n        train_dir(3),\n        LANGUAGES,\n        tokenizer,\n        train=True,\n        val_size=0.2,\n        random_state=42,\n        stratify=False,\n    ),\n]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for subtask_id in [2, 3]:\n\n    init_seed(42)\n\n    experiment_label = f\"{checkpoint.split('/')[-1]}-s_id{subtask_id}\"\n    \n    model = PolarModel(checkpoint, len(dataset[subtask_id-2][\"labels\"]), [])\n    model.to(device)\n    \n    trainer = PolarTrainer(\n        model=model,\n        args=training_args,\n        train_dataset=dataset[subtask_id-2][\"train_dataset\"],\n        eval_dataset=dataset[subtask_id-2][\"val_dataset\"],    \n        compute_metrics=compute_metrics,\n        data_collator=DataCollatorWithPadding(tokenizer)\n    )\n    \n    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=3))\n    \n    trainer.train()\n    \n    eval_results = trainer.evaluate()\n    \n    experiment_results[experiment_label] = eval_results\n    \n    compile_submission(\n        f'{experiment_label}.zip',\n        data_dir=dev_dir(subtask_id),\n        output_dir=os.path.join(ROOT_DIR, f\"subtask_{subtask_id}\"),\n        languages=LANGUAGES,\n        model=model,\n        thresh=0.5,\n        tokenizer=tokenizer,\n        batch_size=BATCH_SIZE,\n        device=device,\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for subtask_id in [2, 3]:\n\n    init_seed(42)\n\n    experiment_label = f\"{checkpoint.split('/')[-1]}-w-s_id{subtask_id}\"\n    \n    model = PolarModel(checkpoint, len(dataset[subtask_id-2][\"labels\"]), [], weights=dataset[subtask_id-2][\"weights\"].to(device))\n    model.to(device)\n    \n    trainer = PolarTrainer(\n        model=model,\n        args=training_args,\n        train_dataset=dataset[subtask_id-2][\"train_dataset\"],\n        eval_dataset=dataset[subtask_id-2][\"val_dataset\"],    \n        compute_metrics=compute_metrics,\n        data_collator=DataCollatorWithPadding(tokenizer)\n    )\n    \n    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=3))\n    \n    trainer.train()\n    \n    eval_results = trainer.evaluate()\n    \n    experiment_results[experiment_label] = eval_results\n    \n    compile_submission(\n        f'{experiment_label}.zip',\n        data_dir=dev_dir(subtask_id),\n        output_dir=os.path.join(ROOT_DIR, f\"subtask_{subtask_id}\"),\n        languages=LANGUAGES,\n        model=model,\n        thresh=0.5,\n        tokenizer=tokenizer,\n        batch_size=BATCH_SIZE,\n        device=device,\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for subtask_id in [2, 3]:\n\n    init_seed(42)\n\n    experiment_label = f\"{checkpoint.split('/')[-1]}-fl-s_id{subtask_id}\"\n    \n    model = PolarModel(checkpoint, len(dataset[subtask_id-2][\"labels\"]), [], criterion=\"focal\")\n    model.to(device)\n    \n    trainer = PolarTrainer(\n        model=model,\n        args=training_args,\n        train_dataset=dataset[subtask_id-2][\"train_dataset\"],\n        eval_dataset=dataset[subtask_id-2][\"val_dataset\"],    \n        compute_metrics=compute_metrics,\n        data_collator=DataCollatorWithPadding(tokenizer)\n    )\n    \n    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=3))\n    \n    trainer.train()\n    \n    eval_results = trainer.evaluate()\n    \n    experiment_results[experiment_label] = eval_results\n    \n    compile_submission(\n        f'{experiment_label}.zip',\n        data_dir=dev_dir(subtask_id),\n        output_dir=os.path.join(ROOT_DIR, f\"subtask_{subtask_id}\"),\n        languages=LANGUAGES,\n        model=model,\n        thresh=0.5,\n        tokenizer=tokenizer,\n        batch_size=BATCH_SIZE,\n        device=device,\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for subtask_id in [2, 3]:\n\n    init_seed(42)\n\n    experiment_label = f\"{checkpoint.split('/')[-1]}-fl-b-s_id{subtask_id}\"\n    \n    model = PolarModel(checkpoint, len(dataset[subtask_id-2][\"labels\"]), [], criterion=\"focal\", alpha=dataset[subtask_id-2][\"weights\"].to(device))\n    model.to(device)\n    \n    trainer = PolarTrainer(\n        model=model,\n        args=training_args,\n        train_dataset=dataset[subtask_id-2][\"train_dataset\"],\n        eval_dataset=dataset[subtask_id-2][\"val_dataset\"],    \n        compute_metrics=compute_metrics,\n        data_collator=DataCollatorWithPadding(tokenizer)\n    )\n    \n    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=3))\n    \n    trainer.train()\n    \n    eval_results = trainer.evaluate()\n    \n    experiment_results[experiment_label] = eval_results\n    \n    compile_submission(\n        f'{experiment_label}.zip',\n        data_dir=dev_dir(subtask_id),\n        output_dir=os.path.join(ROOT_DIR, f\"subtask_{subtask_id}\"),\n        languages=LANGUAGES,\n        model=model,\n        thresh=0.5,\n        tokenizer=tokenizer,\n        batch_size=BATCH_SIZE,\n        device=device,\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame(experiment_results).to_json(\"results.json\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\n\nrm -rf dev_phase.zip\nrm -rf Polar-SemEval-2026-Task-9 src\nrm -rf subtask* checkpoint*\nrm -rf run*","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}