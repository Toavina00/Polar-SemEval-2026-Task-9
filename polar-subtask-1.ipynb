{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14063842,"sourceType":"datasetVersion","datasetId":8951685}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import csv\nimport os\nimport shutil\nimport zipfile\nimport json\n\nimport pandas as pd\nimport numpy as np\nimport torch\n\nfrom collections import OrderedDict\n\nfrom sklearn.metrics import recall_score, precision_score, f1_score\nfrom sklearn.model_selection import train_test_split\n\nfrom transformers.modeling_outputs import SequenceClassifierOutput\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoConfig,\n    AutoModel,\n    Trainer,\n    TrainingArguments,\n    TrainerCallback,\n    EarlyStoppingCallback,\n    DataCollatorWithPadding,\n    get_linear_schedule_with_warmup\n)\n\nimport wandb\nwandb.init(mode=\"disabled\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T06:37:10.748711Z","iopub.execute_input":"2025-12-10T06:37:10.749352Z","iopub.status.idle":"2025-12-10T06:37:10.763924Z","shell.execute_reply.started":"2025-12-10T06:37:10.749328Z","shell.execute_reply":"2025-12-10T06:37:10.763082Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/qqm81hfn?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7fad26c33490>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# @title Submission utils\n\ndef prepare_submission(\n    item_ids: pd.Series,\n    texts: pd.Series,\n    labels,\n    model,\n    tokenizer,\n    batch_size,\n    device,\n) -> str:\n\n    item_ids = item_ids.to_numpy()\n    dev_dataset = PolarDataset(texts.tolist(), [], tokenizer, train=False)\n    dataloader = torch.utils.data.DataLoader(\n        dev_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        collate_fn=DataCollatorWithPadding(tokenizer)\n    )\n\n    outputs = []\n    out_class = len(labels)\n\n    for item in dataloader:\n        ids = item_ids[item[\"idx\"]]\n        preds = model(input_ids=item[\"input_ids\"].to(device), attention_mask=item[\"attention_mask\"].to(device)).logits\n        preds = torch.sigmoid(preds)\n        preds = (preds > 0.5).int()\n\n        for id, pred in zip(ids, preds):\n            outputs.append([id] + [str(p.item()) for p in pred])\n\n    return outputs\n\ndef save_submission(filename, rows, *header):\n    with open(filename, \"w\", newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(header)\n        writer.writerows(rows)\n    \n\ndef compile_submission(\n    root,\n    filename,\n    subtask_id,\n    langs,\n    labels,\n    model,\n    tokenizer,\n    batch_size,\n    device,\n):\n    subtask_dir = f\"subtask_{subtask_id}\"\n    \n    if os.path.exists(subtask_dir):\n        shutil.rmtree(subtask_dir)\n        \n    os.makedirs(subtask_dir)\n    \n    for lang in langs:\n        pred_file = f\"pred_{lang}.csv\"\n        \n        dev = pd.read_csv(os.path.join(root, f'subtask{subtask_id}/dev/{lang}.csv'))\n    \n        submission = prepare_submission(\n            dev['id'],\n            dev['text'],\n            labels,\n            model,\n            tokenizer,\n            batch_size,\n            device,\n        )\n    \n        save_submission(pred_file, submission, \"id\", *labels)\n    \n        shutil.move(pred_file, os.path.join(subtask_dir, pred_file))\n\n    with zipfile.ZipFile(filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, _, files in os.walk(subtask_dir):\n            for file in files:\n                zip_path = os.path.join(root, file)\n                zipf.write(zip_path, arcname=zip_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T06:35:23.315164Z","iopub.execute_input":"2025-12-10T06:35:23.315727Z","iopub.status.idle":"2025-12-10T06:35:23.325714Z","shell.execute_reply.started":"2025-12-10T06:35:23.315704Z","shell.execute_reply":"2025-12-10T06:35:23.324953Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# @title Pytorch Dataset\n\nclass PolarDataset(torch.utils.data.Dataset):\n  def __init__(self, texts, labels, tokenizer, train=True, max_length = 128):\n    self.texts = texts\n    self.labels = labels\n    self.tokenizer = tokenizer\n    self.max_length = max_length\n    self.train = train\n\n  def __len__(self):\n    return len(self.texts)\n\n  def __getitem__(self,idx):\n    text = self.texts[idx]\n    encoding = self.tokenizer(\n        text,\n        truncation=True,\n        padding=False,\n        max_length=self.max_length,\n        return_tensors='pt'\n    )\n\n    item = {key: encoding[key].squeeze() for key in encoding.keys()}\n\n    if self.train:\n        label = self.labels[idx]\n        item['labels'] = torch.tensor(label, dtype=torch.float)\n\n    item['idx'] = torch.tensor(idx, dtype=torch.long)\n    return item","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T06:35:27.557320Z","iopub.execute_input":"2025-12-10T06:35:27.557923Z","iopub.status.idle":"2025-12-10T06:35:27.564412Z","shell.execute_reply.started":"2025-12-10T06:35:27.557900Z","shell.execute_reply":"2025-12-10T06:35:27.563395Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data_eng = pd.read_csv('/kaggle/input/polar-semeval-2026-task-9-dev/subtask1/train/eng.csv')\ndata_swa = pd.read_csv('/kaggle/input/polar-semeval-2026-task-9-dev/subtask1/train/swa.csv')\ndata_hau = pd.read_csv('/kaggle/input/polar-semeval-2026-task-9-dev/subtask1/train/hau.csv')\n\ntrain_eng, val_eng = train_test_split(data_eng, test_size=0.2, random_state=42, stratify=data_eng['polarization'])\ntrain_swa, val_swa = train_test_split(data_swa, test_size=0.2, random_state=42, stratify=data_swa['polarization'])\ntrain_hau, val_hau = train_test_split(data_hau, test_size=0.2, random_state=42, stratify=data_hau['polarization'])\n\ntrain = pd.concat([train_eng, train_swa, train_hau])\nval = pd.concat([val_eng, val_swa, val_hau])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T06:35:30.068787Z","iopub.execute_input":"2025-12-10T06:35:30.069109Z","iopub.status.idle":"2025-12-10T06:35:30.213399Z","shell.execute_reply.started":"2025-12-10T06:35:30.069084Z","shell.execute_reply":"2025-12-10T06:35:30.212792Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"pretrained = [\n    \"google-bert/bert-base-multilingual-cased\",\n    \"FacebookAI/xlm-roberta-base\",\n    \"microsoft/mdeberta-v3-base\",\n    \"jhu-clsp/mmBERT-base\",\n]\n\nROOT_DIR = \"./\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T06:35:33.800426Z","iopub.execute_input":"2025-12-10T06:35:33.800804Z","iopub.status.idle":"2025-12-10T06:35:33.805336Z","shell.execute_reply.started":"2025-12-10T06:35:33.800768Z","shell.execute_reply":"2025-12-10T06:35:33.804144Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# @title Custom model\nclass PolarModel(torch.nn.Module):\n    def __init__(self, checkpoint, num_labels, *hidden_layers, weights=None):\n        super(PolarModel, self).__init__()\n        \n        self.num_labels = num_labels\n        self.criterion = torch.nn.BCEWithLogitsLoss(pos_weight=weights)\n\n        self.config = AutoConfig.from_pretrained(checkpoint)\n        self.base_model = AutoModel.from_pretrained(checkpoint, config=self.config)\n\n        dense = []\n        \n        if len(hidden_layers) > 0:\n            hidden_layers = [self.config.hidden_size] + list(hidden_layers)\n            \n            for i in range(len(hidden_layers) - 1):\n                dense.append(torch.nn.Linear(hidden_layers[i], hidden_layers[i+1]))\n                dense.append(torch.nn.Dropout(0.3))\n                dense.append(torch.nn.ReLU())\n\n        output = torch.nn.Linear(hidden_layers[-1] if len(hidden_layers) > 0 else self.config.hidden_size, self.num_labels)\n        \n        self.classifier = torch.nn.Sequential(\n            *dense,\n            torch.nn.Dropout(0.3),\n            output,\n        )\n        \n\n    def forward(self, input_ids=None, attention_mask=None, labels=None):\n        \n        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = self.classifier(outputs.last_hidden_state[:, 0, :])\n\n        loss = None\n        if labels is not None:\n            loss = self.criterion(logits.view(*labels.shape), labels)\n\n        return SequenceClassifierOutput(\n            loss=loss,\n            logits=logits,\n            hidden_states=outputs.hidden_states,\n            attentions=outputs.attentions,\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T06:35:39.982443Z","iopub.execute_input":"2025-12-10T06:35:39.983076Z","iopub.status.idle":"2025-12-10T06:35:39.990401Z","shell.execute_reply.started":"2025-12-10T06:35:39.983049Z","shell.execute_reply":"2025-12-10T06:35:39.989481Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def compute_metrics(p):\n    probs = torch.sigmoid(torch.from_numpy(p.predictions))\n    preds = (probs > 0.5).int().numpy()\n    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}\n\ntraining_args = TrainingArguments(\n        output_dir=f\"./\",\n        num_train_epochs=10,\n        learning_rate=1e-5,\n        weight_decay=0.01,\n        lr_scheduler_type='linear',\n        per_device_train_batch_size=32,\n        per_device_eval_batch_size=32,\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        save_total_limit=2,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"eval_loss\",\n        greater_is_better=False,\n        logging_steps=100,\n        disable_tqdm=False\n    )\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:14:25.429887Z","iopub.execute_input":"2025-12-09T15:14:25.430647Z","iopub.status.idle":"2025-12-09T15:14:25.464846Z","shell.execute_reply.started":"2025-12-09T15:14:25.430621Z","shell.execute_reply":"2025-12-09T15:14:25.464257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for checkpoint in pretrained:\n\n    np.random.seed(42)\n    torch.manual_seed(42)\n    torch.cuda.manual_seed(42)\n\n    experiment_label = f\"{checkpoint.split('/')[-1]}\"\n    \n    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n    train_dataset = PolarDataset(train['text'].tolist(), train['polarization'].tolist(), tokenizer)\n    val_dataset = PolarDataset(val['text'].tolist(), val['polarization'].tolist(), tokenizer)\n    \n    model = PolarModel(checkpoint, 1)\n    model.to(device)\n    \n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,    \n        compute_metrics=compute_metrics,\n        data_collator=DataCollatorWithPadding(tokenizer)\n    )\n    \n    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=3))\n    \n    trainer.train()\n    \n    eval_results = trainer.evaluate()\n    \n    compile_submission(\n        ROOT_DIR,\n        f\"{experiment_label}.zip\",\n        subtask_id=1,\n        langs=[\"eng\", \"swa\", \"hau\"],\n        labels=['polarization'],\n        model=model,\n        tokenizer=tokenizer,\n        batch_size=32,\n        device=device,\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T14:30:29.361854Z","iopub.execute_input":"2025-12-09T14:30:29.362475Z","iopub.status.idle":"2025-12-09T14:43:26.005526Z","shell.execute_reply.started":"2025-12-09T14:30:29.362451Z","shell.execute_reply":"2025-12-09T14:43:26.004790Z"}},"outputs":[],"execution_count":null}]}